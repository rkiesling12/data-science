{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Launch the installer to download \"movie_reviews\" corpora.\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, I will model the nltk movie reviews data using bag of words and tf idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews, stopwords\n",
    "\n",
    "# Grab and process the raw data\n",
    "\n",
    "positive_reviews = []\n",
    "negative_reviews = []\n",
    "    \n",
    "for fileid in movie_reviews.fileids('pos'):\n",
    "        positive_reviews.append((movie_reviews.raw(fileid)))\n",
    "        \n",
    "for fileid in movie_reviews.fileids('neg'):\n",
    "        negative_reviews.append((movie_reviews.raw(fileid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = re.sub('\\\\\\\\', '', text)\n",
    "    text = re.sub('\\d', '', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "positive = text_cleaner(str(positive_reviews)[:int(len(str(positive_reviews))/100)])\n",
    "negative = text_cleaner(str(negative_reviews)[:int(len(str(negative_reviews))/100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "positive_doc = nlp(positive)\n",
    "negative_doc = nlp(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([, ', films, adapted, from, comic, books, hav...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(nfor, starters, ,, it, was, created, by, alan...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(nto, say, moore, and, campbell, thoroughly, r...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(the, ripper, would, be, like, saying, michael...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(nthe, book, (, or, \", graphic, novel, ,, \", i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0         1\n",
       "0  ([, ', films, adapted, from, comic, books, hav...  positive\n",
       "1  (nfor, starters, ,, it, was, created, by, alan...  positive\n",
       "2  (nto, say, moore, and, campbell, thoroughly, r...  positive\n",
       "3  (the, ripper, would, be, like, saying, michael...  positive\n",
       "4  (nthe, book, (, or, \", graphic, novel, ,, \", i...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "positive_sents = [[sent, \"positive\"] for sent in positive_doc.sents]\n",
    "negative_sents = [[sent, \"negative\"] for sent in negative_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(positive_sents + negative_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['sentiment'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "positivewords = bag_of_words(positive_doc)\n",
    "negativewords = bag_of_words(negative_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(positivewords + negativewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "Processing row 200\n",
      "Processing row 250\n",
      "Processing row 300\n",
      "Processing row 350\n",
      "Processing row 400\n",
      "Processing row 450\n",
      "Processing row 500\n",
      "Processing row 550\n",
      "Processing row 600\n",
      "Processing row 650\n",
      "Processing row 700\n",
      "Processing row 750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bored</th>\n",
       "      <th>rabie</th>\n",
       "      <th>ndid</th>\n",
       "      <th>nevent</th>\n",
       "      <th>ambulance</th>\n",
       "      <th>care</th>\n",
       "      <th>equally</th>\n",
       "      <th>nis</th>\n",
       "      <th>prim</th>\n",
       "      <th>fischer</th>\n",
       "      <th>...</th>\n",
       "      <th>witted</th>\n",
       "      <th>salary</th>\n",
       "      <th>dangerous</th>\n",
       "      <th>episode</th>\n",
       "      <th>young</th>\n",
       "      <th>jock</th>\n",
       "      <th>kick</th>\n",
       "      <th>contrivance</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>([, ', films, adapted, from, comic, books, hav...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(nfor, starters, ,, it, was, created, by, alan...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(nto, say, moore, and, campbell, thoroughly, r...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(the, ripper, would, be, like, saying, michael...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(nthe, book, (, or, \", graphic, novel, ,, \", i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3041 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  bored rabie ndid nevent ambulance care equally nis prim fischer  ... witted  \\\n",
       "0     0     0    0      0         0    0       0   0    0       0  ...      0   \n",
       "1     0     0    0      0         0    0       0   0    0       0  ...      0   \n",
       "2     0     0    0      0         0    0       0   0    0       0  ...      0   \n",
       "3     0     0    0      0         0    0       0   0    0       0  ...      0   \n",
       "4     0     0    0      0         0    0       0   0    0       0  ...      0   \n",
       "\n",
       "  salary dangerous episode young jock kick contrivance  \\\n",
       "0      0         0       0     0    0    0           0   \n",
       "1      0         0       0     0    0    0           0   \n",
       "2      0         0       0     0    0    0           0   \n",
       "3      0         0       0     0    0    0           0   \n",
       "4      0         0       0     0    0    0           0   \n",
       "\n",
       "                                       text_sentence sentiment  \n",
       "0  ([, ', films, adapted, from, comic, books, hav...  positive  \n",
       "1  (nfor, starters, ,, it, was, created, by, alan...  positive  \n",
       "2  (nto, say, moore, and, campbell, thoroughly, r...  positive  \n",
       "3  (the, ripper, would, be, like, saying, michael...  positive  \n",
       "4  (nthe, book, (, or, \", graphic, novel, ,, \", i...  positive  \n",
       "\n",
       "[5 rows x 3041 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52830189 0.60126582 0.60126582 0.53797468 0.53164557]\n",
      "Average Accuracy: 0.56 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['sentiment']\n",
    "X = np.array(word_counts.drop(['text_sentence','sentiment'], 1))\n",
    "rfc.fit(X, Y)\n",
    "score = cross_val_score(rfc, X, Y, cv=5, scoring = 'accuracy')\n",
    "print(score)\n",
    "print('Average Accuracy: %0.2f (+/- %0.2f)' % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55974843 0.58860759 0.61392405 0.58227848 0.70253165]\n",
      "Average Accuracy: 0.61 (+/- 0.10)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2') # No need to specify l2 as it's the default. But we put it for demonstration.\n",
    "lr.fit(X, Y)\n",
    "score = cross_val_score(lr, X, Y, cv=5, scoring = 'accuracy')\n",
    "print(score)\n",
    "print('Average Accuracy: %0.2f (+/- %0.2f)' % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49685535 0.55696203 0.67088608 0.60126582 0.66455696]\n",
      "Average Accuracy: 0.60 (+/- 0.13)\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf.fit(X, Y)\n",
    "score = cross_val_score(clf, X, Y, cv=5, scoring = 'accuracy')\n",
    "print(score)\n",
    "print('Average Accuracy: %0.2f (+/- %0.2f)' % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55974843 0.50632911 0.59493671 0.48101266 0.69620253]\n",
      "Average Accuracy: 0.57 (+/- 0.15)\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X, Y)\n",
    "score = cross_val_score(svc, X, Y, cv=5, scoring = 'accuracy')\n",
    "print(score)\n",
    "print('Average Accuracy: %0.2f (+/- %0.2f)' % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "moviedir = r'C:\\\\Users\\\\rkies\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\movie_reviews'\n",
    "\n",
    "# loading all files. \n",
    "movie = load_files(moviedir, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(movie.data, movie.target, \n",
    "                                                          test_size = 0.20, random_state = 12)\n",
    "movieVzer= CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize, max_features=3000) # use top 3000 words only. 78.25% acc.\n",
    "# movieVzer = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize)         # use all 25K words. Higher accuracy\n",
    "\n",
    "# fit and tranform using training text \n",
    "docs_train_counts = movieVzer.fit_transform(docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw frequency counts into TF-IDF values\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "movieTfmer = TfidfTransformer()\n",
    "docs_train_tfidf = movieTfmer.fit_transform(docs_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the fitted vectorizer and transformer, tranform the test data\n",
    "docs_test_counts = movieVzer.transform(docs_test)\n",
    "docs_test_tfidf = movieTfmer.transform(docs_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79375  0.825    0.79375  0.821875 0.709375]\n",
      "Average Accuracy: 0.79 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc.fit(docs_train_tfidf, y_train)\n",
    "score = cross_val_score(rfc, docs_train_tfidf, y_train, cv=5, scoring = 'accuracy')\n",
    "print(score)\n",
    "print('Average Accuracy: %0.2f (+/- %0.2f)' % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.815625 0.825    0.759375 0.7875   0.76875 ]\n",
      "Average Accuracy: 0.79 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2') # No need to specify l2 as it's the default. But we put it for demonstration.\n",
    "lr.fit(docs_train_tfidf, y_train)\n",
    "score = cross_val_score(lr, docs_train_tfidf, y_train, cv=5, scoring = 'accuracy')\n",
    "print(score)\n",
    "print('Average Accuracy: %0.2f (+/- %0.2f)' % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8      0.809375 0.778125 0.825    0.7625  ]\n",
      "Average Accuracy: 0.80 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf.fit(docs_train_tfidf, y_train)\n",
    "score = cross_val_score(clf, docs_train_tfidf, y_train, cv=5, scoring = 'accuracy')\n",
    "print(score)\n",
    "print('Average Accuracy: %0.2f (+/- %0.2f)' % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8      0.81875  0.80625  0.84375  0.771875]\n",
      "Average Accuracy: 0.81 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier(n_estimators = 250)\n",
    "clf.fit(docs_train_tfidf, y_train)\n",
    "score = cross_val_score(clf, docs_train_tfidf, y_train, cv=5, scoring = 'accuracy')\n",
    "print(score)\n",
    "print('Average Accuracy: %0.2f (+/- %0.2f)' % (score.mean(), score.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
